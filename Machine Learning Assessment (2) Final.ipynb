{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ff07ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6917562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_23524\\1194508237.py:1: DtypeWarning: Columns (47,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('C:\\\\Users\\\\priya\\\\Downloads\\\\archive (5)\\\\bottle.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\priya\\\\Downloads\\\\archive (5)\\\\bottle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f6f00406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cst_Cnt</th>\n",
       "      <th>Btl_Cnt</th>\n",
       "      <th>Sta_ID</th>\n",
       "      <th>Depth_ID</th>\n",
       "      <th>Depthm</th>\n",
       "      <th>T_degC</th>\n",
       "      <th>Salnty</th>\n",
       "      <th>O2ml_L</th>\n",
       "      <th>STheta</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>...</th>\n",
       "      <th>R_PHAEO</th>\n",
       "      <th>R_PRES</th>\n",
       "      <th>R_SAMP</th>\n",
       "      <th>DIC1</th>\n",
       "      <th>DIC2</th>\n",
       "      <th>TA1</th>\n",
       "      <th>TA2</th>\n",
       "      <th>pH2</th>\n",
       "      <th>pH1</th>\n",
       "      <th>DIC Quality Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>054.0 056.0</td>\n",
       "      <td>19-4903CR-HY-060-0930-05400560-0000A-3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>33.440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>054.0 056.0</td>\n",
       "      <td>19-4903CR-HY-060-0930-05400560-0008A-3</td>\n",
       "      <td>8</td>\n",
       "      <td>10.46</td>\n",
       "      <td>33.440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>054.0 056.0</td>\n",
       "      <td>19-4903CR-HY-060-0930-05400560-0010A-7</td>\n",
       "      <td>10</td>\n",
       "      <td>10.46</td>\n",
       "      <td>33.437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>054.0 056.0</td>\n",
       "      <td>19-4903CR-HY-060-0930-05400560-0019A-3</td>\n",
       "      <td>19</td>\n",
       "      <td>10.45</td>\n",
       "      <td>33.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>054.0 056.0</td>\n",
       "      <td>19-4903CR-HY-060-0930-05400560-0020A-7</td>\n",
       "      <td>20</td>\n",
       "      <td>10.45</td>\n",
       "      <td>33.421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cst_Cnt  Btl_Cnt       Sta_ID                                Depth_ID  \\\n",
       "0        1        1  054.0 056.0  19-4903CR-HY-060-0930-05400560-0000A-3   \n",
       "1        1        2  054.0 056.0  19-4903CR-HY-060-0930-05400560-0008A-3   \n",
       "2        1        3  054.0 056.0  19-4903CR-HY-060-0930-05400560-0010A-7   \n",
       "3        1        4  054.0 056.0  19-4903CR-HY-060-0930-05400560-0019A-3   \n",
       "4        1        5  054.0 056.0  19-4903CR-HY-060-0930-05400560-0020A-7   \n",
       "\n",
       "   Depthm  T_degC  Salnty  O2ml_L  STheta  O2Sat  ...  R_PHAEO  R_PRES  \\\n",
       "0       0   10.50  33.440     NaN  25.649    NaN  ...      NaN       0   \n",
       "1       8   10.46  33.440     NaN  25.656    NaN  ...      NaN       8   \n",
       "2      10   10.46  33.437     NaN  25.654    NaN  ...      NaN      10   \n",
       "3      19   10.45  33.420     NaN  25.643    NaN  ...      NaN      19   \n",
       "4      20   10.45  33.421     NaN  25.643    NaN  ...      NaN      20   \n",
       "\n",
       "   R_SAMP  DIC1  DIC2  TA1  TA2  pH2  pH1  DIC Quality Comment  \n",
       "0     NaN   NaN   NaN  NaN  NaN  NaN  NaN                  NaN  \n",
       "1     NaN   NaN   NaN  NaN  NaN  NaN  NaN                  NaN  \n",
       "2     NaN   NaN   NaN  NaN  NaN  NaN  NaN                  NaN  \n",
       "3     NaN   NaN   NaN  NaN  NaN  NaN  NaN                  NaN  \n",
       "4     NaN   NaN   NaN  NaN  NaN  NaN  NaN                  NaN  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8eebd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 864863 entries, 0 to 864862\n",
      "Data columns (total 74 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Cst_Cnt              864863 non-null  int64  \n",
      " 1   Btl_Cnt              864863 non-null  int64  \n",
      " 2   Sta_ID               864863 non-null  object \n",
      " 3   Depth_ID             864863 non-null  object \n",
      " 4   Depthm               864863 non-null  int64  \n",
      " 5   T_degC               853900 non-null  float64\n",
      " 6   Salnty               817509 non-null  float64\n",
      " 7   O2ml_L               696201 non-null  float64\n",
      " 8   STheta               812174 non-null  float64\n",
      " 9   O2Sat                661274 non-null  float64\n",
      " 10  Oxy_µmol/Kg          661268 non-null  float64\n",
      " 11  BtlNum               118667 non-null  float64\n",
      " 12  RecInd               864863 non-null  int64  \n",
      " 13  T_prec               853900 non-null  float64\n",
      " 14  T_qual               23127 non-null   float64\n",
      " 15  S_prec               817509 non-null  float64\n",
      " 16  S_qual               74914 non-null   float64\n",
      " 17  P_qual               673755 non-null  float64\n",
      " 18  O_qual               184676 non-null  float64\n",
      " 19  SThtaq               65823 non-null   float64\n",
      " 20  O2Satq               217797 non-null  float64\n",
      " 21  ChlorA               225272 non-null  float64\n",
      " 22  Chlqua               639166 non-null  float64\n",
      " 23  Phaeop               225271 non-null  float64\n",
      " 24  Phaqua               639170 non-null  float64\n",
      " 25  PO4uM                413317 non-null  float64\n",
      " 26  PO4q                 451786 non-null  float64\n",
      " 27  SiO3uM               354091 non-null  float64\n",
      " 28  SiO3qu               510866 non-null  float64\n",
      " 29  NO2uM                337576 non-null  float64\n",
      " 30  NO2q                 529474 non-null  float64\n",
      " 31  NO3uM                337403 non-null  float64\n",
      " 32  NO3q                 529933 non-null  float64\n",
      " 33  NH3uM                64962 non-null   float64\n",
      " 34  NH3q                 808299 non-null  float64\n",
      " 35  C14As1               14432 non-null   float64\n",
      " 36  C14A1p               12760 non-null   float64\n",
      " 37  C14A1q               848605 non-null  float64\n",
      " 38  C14As2               14414 non-null   float64\n",
      " 39  C14A2p               12742 non-null   float64\n",
      " 40  C14A2q               848623 non-null  float64\n",
      " 41  DarkAs               22649 non-null   float64\n",
      " 42  DarkAp               20457 non-null   float64\n",
      " 43  DarkAq               840440 non-null  float64\n",
      " 44  MeanAs               22650 non-null   float64\n",
      " 45  MeanAp               20457 non-null   float64\n",
      " 46  MeanAq               840439 non-null  float64\n",
      " 47  IncTim               14437 non-null   object \n",
      " 48  LightP               18651 non-null   float64\n",
      " 49  R_Depth              864863 non-null  float64\n",
      " 50  R_TEMP               853900 non-null  float64\n",
      " 51  R_POTEMP             818816 non-null  float64\n",
      " 52  R_SALINITY           817509 non-null  float64\n",
      " 53  R_SIGMA              812007 non-null  float64\n",
      " 54  R_SVA                812092 non-null  float64\n",
      " 55  R_DYNHT              818206 non-null  float64\n",
      " 56  R_O2                 696201 non-null  float64\n",
      " 57  R_O2Sat              666448 non-null  float64\n",
      " 58  R_SIO3               354099 non-null  float64\n",
      " 59  R_PO4                413325 non-null  float64\n",
      " 60  R_NO3                337411 non-null  float64\n",
      " 61  R_NO2                337584 non-null  float64\n",
      " 62  R_NH4                64982 non-null   float64\n",
      " 63  R_CHLA               225276 non-null  float64\n",
      " 64  R_PHAEO              225275 non-null  float64\n",
      " 65  R_PRES               864863 non-null  int64  \n",
      " 66  R_SAMP               122006 non-null  float64\n",
      " 67  DIC1                 1999 non-null    float64\n",
      " 68  DIC2                 224 non-null     float64\n",
      " 69  TA1                  2084 non-null    float64\n",
      " 70  TA2                  234 non-null     float64\n",
      " 71  pH2                  10 non-null      float64\n",
      " 72  pH1                  84 non-null      float64\n",
      " 73  DIC Quality Comment  55 non-null      object \n",
      "dtypes: float64(65), int64(5), object(4)\n",
      "memory usage: 488.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03ad7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_values = df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b85ead24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['T_degC', 'Salnty', 'O2ml_L', 'STheta', 'O2Sat', 'Oxy_µmol/Kg',\n",
       "       'BtlNum', 'T_prec', 'T_qual', 'S_prec', 'S_qual', 'P_qual', 'O_qual',\n",
       "       'SThtaq', 'O2Satq', 'ChlorA', 'Chlqua', 'Phaeop', 'Phaqua', 'PO4uM',\n",
       "       'PO4q', 'SiO3uM', 'SiO3qu', 'NO2uM', 'NO2q', 'NO3uM', 'NO3q', 'NH3uM',\n",
       "       'NH3q', 'C14As1', 'C14A1p', 'C14A1q', 'C14As2', 'C14A2p', 'C14A2q',\n",
       "       'DarkAs', 'DarkAp', 'DarkAq', 'MeanAs', 'MeanAp', 'MeanAq', 'IncTim',\n",
       "       'LightP', 'R_TEMP', 'R_POTEMP', 'R_SALINITY', 'R_SIGMA', 'R_SVA',\n",
       "       'R_DYNHT', 'R_O2', 'R_O2Sat', 'R_SIO3', 'R_PO4', 'R_NO3', 'R_NO2',\n",
       "       'R_NH4', 'R_CHLA', 'R_PHAEO', 'R_SAMP', 'DIC1', 'DIC2', 'TA1', 'TA2',\n",
       "       'pH2', 'pH1', 'DIC Quality Comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b72798e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df[['T_degC', 'Salnty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "123451ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_degC</th>\n",
       "      <th>Salnty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.500</td>\n",
       "      <td>33.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.460</td>\n",
       "      <td>33.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.460</td>\n",
       "      <td>33.4370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.450</td>\n",
       "      <td>33.4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.450</td>\n",
       "      <td>33.4210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864858</th>\n",
       "      <td>18.744</td>\n",
       "      <td>33.4083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864859</th>\n",
       "      <td>18.744</td>\n",
       "      <td>33.4083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864860</th>\n",
       "      <td>18.692</td>\n",
       "      <td>33.4150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864861</th>\n",
       "      <td>18.161</td>\n",
       "      <td>33.4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864862</th>\n",
       "      <td>17.533</td>\n",
       "      <td>33.3880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864863 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        T_degC   Salnty\n",
       "0       10.500  33.4400\n",
       "1       10.460  33.4400\n",
       "2       10.460  33.4370\n",
       "3       10.450  33.4200\n",
       "4       10.450  33.4210\n",
       "...        ...      ...\n",
       "864858  18.744  33.4083\n",
       "864859  18.744  33.4083\n",
       "864860  18.692  33.4150\n",
       "864861  18.161  33.4062\n",
       "864862  17.533  33.3880\n",
       "\n",
       "[864863 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fecf20aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T_degC    10963\n",
       "Salnty    47354\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cb0b9e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_nulls = dataset.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b54e90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_columns = ['T_degC', 'Salnty']\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "dataset_copy = dataset.copy()\n",
    "\n",
    "dataset_copy.loc[:, numeric_columns] = imputer.fit_transform(dataset_copy[numeric_columns])\n",
    "\n",
    "dataset.update(dataset_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4163e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              T_degC         Salnty\n",
      "count  864863.000000  864863.000000\n",
      "mean       10.799677      33.840350\n",
      "std         4.216841       0.449022\n",
      "min         1.440000      28.431000\n",
      "25%         7.720000      33.504000\n",
      "50%        10.130000      33.840350\n",
      "75%        13.830000      34.180000\n",
      "max        31.140000      37.034000\n"
     ]
    }
   ],
   "source": [
    "#summary statistics after imputation\n",
    "print(dataset[numeric_columns].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "52ed37fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_degC    0\n",
      "Salnty    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#missing values after imputation\n",
    "print(dataset[numeric_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "57fb79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outliers\n",
    "numeric_columns = ['T_degC', 'Salnty']\n",
    "\n",
    "# Calculate the IQR for each numeric column\n",
    "Q1 = dataset[numeric_columns].quantile(0.25)\n",
    "Q3 = dataset[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_threshold = 1.5\n",
    "\n",
    "#boolean mask for outliers\n",
    "outlier_mask = ((dataset[numeric_columns] < (Q1 - outlier_threshold * IQR)) | (dataset[numeric_columns] > (Q3 + outlier_threshold * IQR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "16eef407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              T_degC         Salnty\n",
      "count  864863.000000  864863.000000\n",
      "mean       10.799677      33.840350\n",
      "std         4.216841       0.449022\n",
      "min         1.440000      28.431000\n",
      "25%         7.720000      33.504000\n",
      "50%        10.130000      33.840350\n",
      "75%        13.830000      34.180000\n",
      "max        31.140000      37.034000\n",
      "T_degC    0\n",
      "Salnty    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#summary statistics after removing outliers\n",
    "print(dataset[numeric_columns].describe())\n",
    "\n",
    "#missing values after removing outliers\n",
    "print(dataset[numeric_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d79bf7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_features = ['Salnty']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a copy to avoid SettingWithCopyWarning\n",
    "dataset_copy = dataset.copy()\n",
    "\n",
    "# Use .loc for proper assignment\n",
    "dataset.loc[:, numeric_features] = scaler.fit_transform(dataset_copy[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7ec34958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Salnty\n",
      "count  8.648630e+05\n",
      "mean  -2.155791e-17\n",
      "std    1.000001e+00\n",
      "min   -1.204698e+01\n",
      "25%   -7.490741e-01\n",
      "50%   -1.954693e-14\n",
      "75%    7.564221e-01\n",
      "max    7.112466e+00\n"
     ]
    }
   ],
   "source": [
    "#summary statistics of scaled features\n",
    "print(dataset[numeric_features].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bc1b034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'X' is dependent and 'y' is target variable\n",
    "X = dataset.drop('T_degC', axis=1)\n",
    "y = dataset['T_degC']\n",
    "\n",
    "#Splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8d9c1f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (691890, 1)\n",
      "X_test shape: (172973, 1)\n",
      "y_train shape: (691890,)\n",
      "y_test shape: (172973,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b423b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample:\n",
      "              Salnty\n",
      "87031  -1.954693e-14\n",
      "42195   1.155067e+00\n",
      "478241  2.595978e+00\n",
      "253676 -2.680280e-01\n",
      "34     -1.337019e+00\n",
      "X_test sample:\n",
      "          Salnty\n",
      "246454  1.446812\n",
      "204226  1.714060\n",
      "34578   0.959085\n",
      "63034   1.825413\n",
      "275018 -0.446193\n",
      "y_train sample:\n",
      "87031      4.30\n",
      "42195      4.61\n",
      "478241    14.07\n",
      "253676    10.21\n",
      "34         9.06\n",
      "Name: T_degC, dtype: float64\n",
      "y_test sample:\n",
      "246454    10.25\n",
      "204226     3.76\n",
      "34578      5.27\n",
      "63034      9.93\n",
      "275018     9.36\n",
      "Name: T_degC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train sample:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"X_test sample:\")\n",
    "print(X_test.head())\n",
    "\n",
    "print(\"y_train sample:\")\n",
    "print(y_train.head())\n",
    "\n",
    "print(\"y_test sample:\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0d22000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c8e72121",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "}\n",
    "linear_regression_model = LinearRegression()\n",
    "grid_search = GridSearchCV(\n",
    "    linear_regression_model,\n",
    "    param_grid,  \n",
    "    scoring='neg_mean_squared_error',  \n",
    "    cv=5  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1bf3d48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'copy_X': True, 'fit_intercept': True}\n",
      "Best Score: -13.516865222287393\n",
      "Best Model: LinearRegression()\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "\n",
    "# Access the best average cross-validated score\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Best Model:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "65e9833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 13.497756716713758\n",
      "R-squared: 0.23909275107658967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Creating and training the Linear Regression model with best hyperparameters\n",
    "best_linear_regression_model = LinearRegression(copy_X=True, fit_intercept=True)\n",
    "best_linear_regression_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = best_linear_regression_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "15f392da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "85fec6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.6859964705515633\n",
      "Mean Squared Error: 13.497756716713758\n",
      "R-squared: 0.23909275107658967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculating(MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print MAE\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ba91952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (MSE): [13.27632552 13.57679859 13.4415977  13.70532582 13.58489948]\n",
      "Mean Cross-Validation MSE: 13.516989421744878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "# Creating KFold object\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Performing k-fold cross-validation\n",
    "cross_val_results = cross_val_score(linear_regression_model, X_train_scaled, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "cross_val_results = -cross_val_results\n",
    "\n",
    "# Printing cross-validation results\n",
    "print(f'Cross-Validation Results (MSE): {cross_val_results}')\n",
    "print(f'Mean Cross-Validation MSE: {cross_val_results.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9ca41f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (MSE): [13.26275529 13.28920708 13.4765184  13.67707465 13.31625166 13.56736489\n",
      " 13.66476654 13.74540424 13.67223611 13.49778628]\n",
      "Mean Cross-Validation MSE: 13.51693651540084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "# Creating KFold object\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Performing k-fold cross-validation\n",
    "cross_val_results = cross_val_score(linear_regression_model, X_train_scaled, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "cross_val_results = -cross_val_results\n",
    "\n",
    "# Printing cross-validation results\n",
    "print(f'Cross-Validation Results (MSE): {cross_val_results}')\n",
    "print(f'Mean Cross-Validation MSE: {cross_val_results.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8a0bb200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 13.497756716713758\n",
      "R-squared on Test Set: 0.23909275107658967\n",
      "Selected Model: Linear Regression with Hyperparameter Tuning\n"
     ]
    }
   ],
   "source": [
    "best_model = LinearRegression(copy_X=True, fit_intercept=True)\n",
    "\n",
    "# Fit the best model on training dataset\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predictions on the test set\n",
    "y_pred_test = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Mean Squared Error on Test Set: {mse_test}')\n",
    "print(f'R-squared on Test Set: {r2_test}')\n",
    "\n",
    "# Justification for Model Selection\n",
    "print(\"Selected Model: Linear Regression with Hyperparameter Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e8b8a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Modelling Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97954dc8",
   "metadata": {},
   "source": [
    "<h1>Classification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af51c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:\\\\Users\\\\priya\\\\Downloads\\\\archive (6)\\\\heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "03dd4a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "656e695e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the df1 now is 296 instead of 303!\n"
     ]
    }
   ],
   "source": [
    "df1 = df1[df1['ca'] < 4] #drop the wrong ca values\n",
    "df1 = df1[df1['thal'] > 0] # drop the wong thal value\n",
    "print(f'The length of the df1 now is {len(df1)} instead of 303!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2adf7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(\n",
    "    columns = {'cp':'chest_pain_type', \n",
    "               'trestbps':'resting_blood_pressure', \n",
    "               'chol': 'cholesterol',\n",
    "               'fbs': 'fasting_blood_sugar',\n",
    "               'restecg' : 'resting_electrocardiogram', \n",
    "               'thalach': 'max_heart_rate_achieved', \n",
    "               'exang': 'exercise_induced_angina',\n",
    "               'oldpeak': 'st_depression', \n",
    "               'slope': 'st_slope', \n",
    "               'ca':'num_major_vessels', \n",
    "               'thal': 'thalassemia'}, \n",
    "    errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5be3b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 296 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   age                        296 non-null    int64  \n",
      " 1   sex                        296 non-null    int64  \n",
      " 2   chest_pain_type            296 non-null    int64  \n",
      " 3   resting_blood_pressure     296 non-null    int64  \n",
      " 4   cholesterol                296 non-null    int64  \n",
      " 5   fasting_blood_sugar        296 non-null    int64  \n",
      " 6   resting_electrocardiogram  296 non-null    int64  \n",
      " 7   max_heart_rate_achieved    296 non-null    int64  \n",
      " 8   exercise_induced_angina    296 non-null    int64  \n",
      " 9   st_depression              296 non-null    float64\n",
      " 10  st_slope                   296 non-null    int64  \n",
      " 11  num_major_vessels          296 non-null    int64  \n",
      " 12  thalassemia                296 non-null    int64  \n",
      " 13  target                     296 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 34.7 KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a201d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_values = df1.columns[df1.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b444bf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21cee12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          0\n",
       "sex                          0\n",
       "chest_pain_type              0\n",
       "resting_blood_pressure       0\n",
       "cholesterol                  0\n",
       "fasting_blood_sugar          0\n",
       "resting_electrocardiogram    0\n",
       "max_heart_rate_achieved      0\n",
       "exercise_induced_angina      0\n",
       "st_depression                0\n",
       "st_slope                     0\n",
       "num_major_vessels            0\n",
       "thalassemia                  0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b32b34f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing outliers: (296, 14)\n",
      "Shape after removing outliers using IQR method: (228, 14)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the IQR for each column\n",
    "Q1 = df1.quantile(0.25)\n",
    "Q3 = df1.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define a threshold to identify outliers (e.g., 1.5 times the IQR)\n",
    "outlier_threshold = 1.5\n",
    "\n",
    "# Find indices of outliers\n",
    "outlier_indices = ((df1 < (Q1 - outlier_threshold * IQR)) | (df1 > (Q3 + outlier_threshold * IQR))).any(axis=1)\n",
    "\n",
    "# Remove outliers\n",
    "df1_no_outliers_iqr = df1[~outlier_indices]\n",
    "\n",
    "# Display the shape before and after removing outliers\n",
    "print(\"Shape before removing outliers:\", df1.shape)\n",
    "print(\"Shape after removing outliers using IQR method:\", df1_no_outliers_iqr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5308a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extracting features (X) and target variable (y)\n",
    "X = df1.drop('target', axis=1)\n",
    "y = df1['target']\n",
    "\n",
    "# Using StandardScaler for feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afbe680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.93721873  0.68748587  1.97643302  0.75693814 -0.27280094  2.42563825\n",
      "  -0.99590459  0.01915184 -0.69816702  1.06558695 -2.26068168 -0.72383218\n",
      "  -2.27053862]\n",
      " [-1.93756618  0.68748587  1.00784995 -0.09067985  0.05482062 -0.41226263\n",
      "   0.90595192  1.63262072 -0.69816702  2.09607016 -2.26068168 -0.72383218\n",
      "  -0.56041284]\n",
      " [-1.49529158 -1.45457536  0.03926688 -0.09067985 -0.83168477 -0.41226263\n",
      "  -0.99590459  0.97851172 -0.69816702  0.29272454  0.97981119 -0.72383218\n",
      "  -0.56041284]\n",
      " [ 0.16323818  0.68748587  0.03926688 -0.65575852 -0.21498537 -0.41226263\n",
      "   0.90595192  1.24015532 -0.69816702 -0.22251707  0.97981119 -0.72383218\n",
      "  -0.56041284]\n",
      " [ 0.27380683 -1.45457536 -0.92931619 -0.65575852  2.05909366 -0.41226263\n",
      "   0.90595192  0.58604631  1.43232203 -0.39426427  0.97981119 -0.72383218\n",
      "  -0.56041284]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Check the first few rows of the scaled features\n",
    "print(X_scaled[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0a87910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                age         sex  chest_pain_type  resting_blood_pressure  \\\n",
      "count  2.960000e+02  296.000000       296.000000            2.960000e+02   \n",
      "mean   3.480699e-16    0.000000         0.000000           -6.001206e-16   \n",
      "std    1.001693e+00    1.001693         1.001693            1.001693e+00   \n",
      "min   -2.822115e+00   -1.454575        -0.929316           -2.124963e+00   \n",
      "25%   -7.213110e-01   -1.454575        -0.929316           -6.557585e-01   \n",
      "50%    1.632382e-01    0.687486         0.039267           -9.067985e-02   \n",
      "75%    7.160814e-01    0.687486         1.007850            4.743988e-01   \n",
      "max    2.485180e+00    0.687486         1.976433            3.864871e+00   \n",
      "\n",
      "        cholesterol  fasting_blood_sugar  resting_electrocardiogram  \\\n",
      "count  2.960000e+02         2.960000e+02               2.960000e+02   \n",
      "mean  -2.340470e-16         1.200241e-17              -9.601929e-17   \n",
      "std    1.001693e+00         1.001693e+00               1.001693e+00   \n",
      "min   -2.334890e+00        -4.122626e-01              -9.959046e-01   \n",
      "25%   -6.967818e-01        -4.122626e-01              -9.959046e-01   \n",
      "50%   -8.971830e-02        -4.122626e-01               9.059519e-01   \n",
      "75%    5.414350e-01        -4.122626e-01               9.059519e-01   \n",
      "max    6.106183e+00         2.425638e+00               2.807808e+00   \n",
      "\n",
      "       max_heart_rate_achieved  exercise_induced_angina  st_depression  \\\n",
      "count             2.960000e+02             2.960000e+02   2.960000e+02   \n",
      "mean              1.920386e-16             1.440289e-16  -9.601929e-17   \n",
      "std               1.001693e+00             1.001693e+00   1.001693e+00   \n",
      "min              -3.425822e+00            -6.981670e-01  -9.095059e-01   \n",
      "25%              -7.221717e-01            -6.981670e-01  -9.095059e-01   \n",
      "50%               1.281700e-01            -6.981670e-01  -2.225171e-01   \n",
      "75%               7.168681e-01             1.432322e+00   5.074085e-01   \n",
      "max               2.286730e+00             1.432322e+00   4.414657e+00   \n",
      "\n",
      "           st_slope  num_major_vessels   thalassemia  \n",
      "count  2.960000e+02       2.960000e+02  2.960000e+02  \n",
      "mean   1.440289e-16       2.400482e-17  1.680338e-16  \n",
      "std    1.001693e+00       1.001693e+00  1.001693e+00  \n",
      "min   -2.260682e+00      -7.238322e-01 -2.270539e+00  \n",
      "25%   -6.404352e-01      -7.238322e-01 -5.604128e-01  \n",
      "50%   -6.404352e-01      -7.238322e-01 -5.604128e-01  \n",
      "75%    9.798112e-01       3.421097e-01  1.149713e+00  \n",
      "max    9.798112e-01       2.473994e+00  1.149713e+00  \n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(X_scaled, columns=X.columns).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2506b515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (236, 13)\n",
      "X_test shape: (60, 13)\n",
      "y_train shape: (236,)\n",
      "y_test shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1.drop('target', axis=1)  # Features\n",
    "y = df1['target']  # Target variable\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09475302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Number Of Components: 10\n",
      "Best Penalty: l2\n",
      "Best C: 0.02811768697974228\n",
      "\n",
      "LogisticRegression(C=0.02811768697974228)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df1.drop('target', axis=1)\n",
    "y = df1['target']\n",
    "\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "logistic_Reg = linear_model.LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('pca', pca),\n",
    "                        ('logistic_Reg', logistic_Reg)])\n",
    "\n",
    "n_components = list(range(1, X.shape[1] + 1, 1))\n",
    "C = np.logspace(-4, 4, 50)\n",
    "penalty = ['l2']\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                  logistic_Reg__C=C,\n",
    "                  logistic_Reg__penalty=penalty)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "clf_GS = GridSearchCV(pipe, parameters, scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "clf_GS.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters and the logistic regression model\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print('Best Penalty:', clf_GS.best_estimator_.get_params()['logistic_Reg__penalty'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['logistic_Reg__C'])\n",
    "print()\n",
    "print(clf_GS.best_estimator_.get_params()['logistic_Reg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "148ab4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Using the best hyperparameters from the grid search\n",
    "best_n_components = 10\n",
    "best_penalty = 'l2'\n",
    "best_C = 0.02811768697974228\n",
    "\n",
    "# Creating the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('std_slc', StandardScaler()),\n",
    "    ('pca', PCA(n_components=best_n_components)),\n",
    "    ('logistic_Reg', LogisticRegression(C=best_C, penalty=best_penalty))\n",
    "])\n",
    "\n",
    "# Fit the model to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "33b05ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      "[[24  4]\n",
      " [ 2 30]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        28\n",
      "           1       0.88      0.94      0.91        32\n",
      "\n",
      "    accuracy                           0.90        60\n",
      "   macro avg       0.90      0.90      0.90        60\n",
      "weighted avg       0.90      0.90      0.90        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2255920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate (Recall): 0.94\n",
      "True Negative Rate (Specificity): 0.86\n",
      "Precision: 0.88\n",
      "F1 Score: 0.91\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        28\n",
      "           1       0.88      0.94      0.91        32\n",
      "\n",
      "    accuracy                           0.90        60\n",
      "   macro avg       0.90      0.90      0.90        60\n",
      "weighted avg       0.90      0.90      0.90        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predictions (y_pred) and actual labels (y_test)\n",
    "y_pred = clf_GS.predict(X_test)\n",
    "\n",
    "# Analyze the confusion matrix\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# True Positive Rate (Recall)\n",
    "sensitivity = TP / (TP + FN)\n",
    "print(f\"True Positive Rate (Recall): {sensitivity:.2f}\")\n",
    "\n",
    "# True Negative Rate (Specificity)\n",
    "specificity = TN / (TN + FP)\n",
    "print(f\"True Negative Rate (Specificity): {specificity:.2f}\")\n",
    "\n",
    "# Precision\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "760a397f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.81666667 0.74576271 0.71186441 0.6779661  0.71186441]\n",
      "Average CV Scores:  0.732824858757062\n",
      "Number of CV Scores used in average:  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Creating a decision tree classifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# (5-fold) Method\n",
    "k_folds = 5\n",
    "\n",
    "# Creating a stratified k-fold object\n",
    "stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(classifier, X, y, cv=stratified_kfold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross Validation Scores: \", cv_scores)\n",
    "print(\"Average CV Scores: \", cv_scores.mean())\n",
    "print(\"Number of CV Scores used in average: \", len(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e5ea864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.66666667 0.86666667 0.63333333 0.76666667 0.7        0.76666667\n",
      " 0.79310345 0.65517241 0.72413793 0.68965517]\n",
      "Average CV Scores:  0.7262068965517241\n",
      "Number of CV Scores used in average:  10\n"
     ]
    }
   ],
   "source": [
    "# Creating a decision tree classifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# (5-fold) Method\n",
    "k_folds = 10\n",
    "\n",
    "# Creating a stratified k-fold object\n",
    "stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(classifier, X, y, cv=stratified_kfold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross Validation Scores: \", cv_scores)\n",
    "print(\"Average CV Scores: \", cv_scores.mean())\n",
    "print(\"Number of CV Scores used in average: \", len(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a27ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Logistic Regression CV Score: 0.8581920903954803\n",
      "Average Decision Tree CV Score: 0.8074576271186441\n",
      "Logistic Regression performs better.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = df1.drop('target', axis=1)\n",
    "y = df1['target']\n",
    "\n",
    "# Logistic Regression hyperparameter tuning\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "logistic_param_grid = {\n",
    "    'pca__n_components': list(range(1, X.shape[1] + 1)),\n",
    "    'classifier__C': np.logspace(-4, 4, 50),\n",
    "    'classifier__penalty': ['l2']\n",
    "}\n",
    "\n",
    "logistic_grid_search = GridSearchCV(logistic_pipeline, logistic_param_grid, scoring='accuracy', cv=5)\n",
    "logistic_grid_search.fit(X, y)\n",
    "\n",
    "# Decision Tree hyperparameter tuning\n",
    "dt_pipeline = Pipeline([\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "dt_param_grid = {\n",
    "    'classifier__max_depth': [3, 5, 7, 10],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_grid_search = GridSearchCV(dt_pipeline, dt_param_grid, scoring='accuracy', cv=5)\n",
    "dt_grid_search.fit(X, y)\n",
    "\n",
    "# Cross-validation scores\n",
    "logistic_cv_scores = cross_val_score(logistic_grid_search.best_estimator_, X, y, cv=5)\n",
    "dt_cv_scores = cross_val_score(dt_grid_search.best_estimator_, X, y, cv=5)\n",
    "\n",
    "# Compare and justify the choice based on average cross-validation scores\n",
    "avg_logistic_cv_score = logistic_cv_scores.mean()\n",
    "avg_dt_cv_score = dt_cv_scores.mean()\n",
    "\n",
    "print(f'Average Logistic Regression CV Score: {avg_logistic_cv_score}')\n",
    "print(f'Average Decision Tree CV Score: {avg_dt_cv_score}')\n",
    "\n",
    "# Compare and justify the choice based on average scores\n",
    "if avg_logistic_cv_score > avg_dt_cv_score:\n",
    "    print('Logistic Regression performs better.')\n",
    "else:\n",
    "    print('Decision Tree performs better.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb2a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
